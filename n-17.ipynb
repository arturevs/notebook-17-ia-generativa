{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac0174d",
   "metadata": {},
   "source": [
    "# Atividade: GANs\n",
    "\n",
    "Neste notebook, você irá **preparar seu próprio dataset** e **treinar uma DCGAN utilizando a distância de Wasserstein**.\n",
    "O objetivo é gerar imagens sintéticas a partir de ruído, aprendendo a distribuição dos dados reais.\n",
    "\n",
    "O treinamento será realizado com um **Gerador** e um **Crítico** (substituindo o discriminador tradicional), aplicando **gradient clipping** para garantir a restrição de Lipschitz exigida pela métrica de Wasserstein.\n",
    "\n",
    "Ao final, o modelo deverá ser capaz de **produzir imagens realistas** a partir de vetores aleatórios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedad1c3",
   "metadata": {},
   "source": [
    "## Preparando os dados\n",
    "\n",
    "Para esta atividade, será necessário baixar ou montar um dataset de imagens de um domínio específico (por exemplo, rostos, paisagens, objetos, etc.). Você pode utilizar datasets públicos como LFW e CelebA ou criar o seu próprio conjunto de imagens armazenadas em uma pasta local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f6339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from icrawler.builtin import BingImageCrawler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03a046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Só resolvendo um probleminha de logging\n",
    "logging.getLogger(\"icrawler\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"parser\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"downloader\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"feeder\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb53e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/images\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "KEYWORD = \"landscape painting\"\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 8\n",
    "Z_DIM = 100\n",
    "NUM_EPOCHS = 150\n",
    "LR = 5e-5\n",
    "CLIP_VALUE = 0.01\n",
    "N_CRITIC = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a562bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71316a9",
   "metadata": {},
   "source": [
    "### Coleta de Imagens\n",
    "\n",
    "Caso opte por montar seu próprio dataset, você pode utilizar a biblioteca iCrawler para baixar imagens automaticamente a partir de buscadores (como Google, Bing ou Baidu), fornecendo uma lista de termos relacionados ao domínio desejado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22940326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(keyword, folder, n_total=200):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    existing = len([f for f in os.listdir(folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    if existing >= n_total:\n",
    "        print(f\"Found {existing} images, skipping download.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Downloading images for '{keyword}'...\")\n",
    "    try:\n",
    "        crawler = BingImageCrawler(storage={'root_dir': folder})\n",
    "        crawler.crawl(keyword=keyword, max_num=n_total)\n",
    "    except Exception as e:\n",
    "        print(f\"Crawler failed: {e}\")\n",
    "\n",
    "    existing = len([f for f in os.listdir(folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    if existing == 0:\n",
    "        print(\"Download failed or no images found. Generating synthetic data for testing...\")\n",
    "        for i in range(n_total):\n",
    "            img = np.random.randint(0, 255, (IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.uint8)\n",
    "            Image.fromarray(img).save(os.path.join(folder, f\"synthetic_{i}.png\"))\n",
    "    \n",
    "    print(\"Data preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039fee3",
   "metadata": {},
   "source": [
    "### Implementação do Dataset\n",
    "\n",
    "Com as imagens já disponíveis, implemente uma **classe de Dataset personalizada** para o PyTorch. Ela deve herdar de `Dataset` e retornar, em cada amostra, a imagem processada pelos **transforms** definidos anteriormente.\n",
    "\n",
    "O Dataset deve:\n",
    "\n",
    "* Ler as imagens a partir de uma pasta.\n",
    "* Converter as imagens para **tensor normalizado** (ex.: valores entre -1 e 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39e2fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.folder = folder\n",
    "        self.transform = transform\n",
    "        self.images = [\n",
    "            os.path.join(folder, f)\n",
    "            for f in os.listdir(folder)\n",
    "            if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            return torch.zeros(3, IMAGE_SIZE, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eac31f",
   "metadata": {},
   "source": [
    "### Carregamento\n",
    "\n",
    "Carregue os dados a partir do seu dataset de imagens e aplique os transforms necessários. Caso o dataset seja pequeno, recomenda-se o uso de data augmentation (como flips horizontais, jitter de cor ou pequenas rotações) para aumentar a diversidade das amostras e melhorar a estabilidade do treinamento adversarial. Em seguida, defina um batch size adequado e instancie um DataLoader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab12706e",
   "metadata": {},
   "source": [
    "## Definição dos Modelos\n",
    "\n",
    "Para este exercício, deverão ser utilizadas DCGANs com distância de Wasserstein. Nesta seção, defina a arquitetura dos modelos Gerador e Crítico, implementando o treinamento adversarial baseado na métrica de Wasserstein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1772e16d",
   "metadata": {},
   "source": [
    "### Gerador\n",
    "\n",
    "O Gerador seguirá a arquitetura típica de uma DCGAN, produzindo amostras sintéticas a partir de vetores de ruído, enquanto o Crítico avaliará a distância entre as distribuições reais e geradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf517a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_channels=3, feature_g=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            self._block(z_dim, feature_g * 8, 4, 1, 0),\n",
    "            self._block(feature_g * 8, feature_g * 4, 4, 2, 1),\n",
    "            self._block(feature_g * 4, feature_g * 2, 4, 2, 1),\n",
    "            self._block(feature_g * 2, feature_g, 4, 2, 1),\n",
    "            nn.ConvTranspose2d(feature_g, img_channels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fde9ec0",
   "metadata": {},
   "source": [
    "### Crítico\n",
    "\n",
    "O Crítico (substituindo o discriminador tradicional) deve utilizar gradient clipping para garantir o cumprimento da restrição de Lipschitz, condição essencial para a estabilidade da função de custo de Wasserstein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4971768",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, img_channels=3, feature_d=64):\n",
    "        super(Critic, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, feature_d, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            self._block(feature_d, feature_d * 2, 4, 2, 1),\n",
    "            self._block(feature_d * 2, feature_d * 4, 4, 2, 1),\n",
    "            self._block(feature_d * 4, feature_d * 8, 4, 2, 1),\n",
    "            nn.Conv2d(feature_d * 8, 1, 4, 1, 0),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5ee44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36832a0",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "Com o **Gerador** e o **Crítico** definidos, e os dados devidamente carregados, inicie o treinamento.\n",
    "\n",
    "Durante o processo:\n",
    "\n",
    "* Atualize o **Crítico** várias vezes para cada atualização do **Gerador**, garantindo uma estimativa mais precisa da distância de Wasserstein.\n",
    "* Aplique **gradient clipping** nos parâmetros do Crítico após cada atualização, mantendo a restrição de **Lipschitz**.\n",
    "* Utilize **losses baseadas na métrica de Wasserstein**.\n",
    "\n",
    "Ao longo do treinamento, **visualize amostras geradas** a cada determinado número de épocas, observando a evolução da qualidade das imagens produzidas pelo Gerador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ff7078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    download_images(KEYWORD, DATA_DIR, n_total=1000)\n",
    "    \n",
    "    transform = T.Compose([\n",
    "        T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "    \n",
    "    dataset = ImageDataset(DATA_DIR, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    gen = Generator(Z_DIM).to(DEVICE)\n",
    "    critic = Critic().to(DEVICE)\n",
    "    initialize_weights(gen)\n",
    "    initialize_weights(critic)\n",
    "    opt_gen = optim.RMSprop(gen.parameters(), lr=LR)\n",
    "    opt_critic = optim.RMSprop(critic.parameters(), lr=LR)\n",
    "    \n",
    "    fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(DEVICE)\n",
    "    \n",
    "    print(\"Starting Training...\")\n",
    "    step = 0\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        loop = tqdm(dataloader, leave=True)\n",
    "        for batch_idx, real in enumerate(loop):\n",
    "            real = real.to(DEVICE)\n",
    "            cur_batch_size = real.shape[0]\n",
    "            for _ in range(N_CRITIC):\n",
    "                noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(DEVICE)\n",
    "                fake = gen(noise)\n",
    "                \n",
    "                critic_real = critic(real).reshape(-1)\n",
    "                critic_fake = critic(fake).reshape(-1)\n",
    "                \n",
    "                loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
    "                \n",
    "                critic.zero_grad()\n",
    "                loss_critic.backward(retain_graph=True)\n",
    "                opt_critic.step()\n",
    "                \n",
    "                for p in critic.parameters():\n",
    "                    p.data.clamp_(-CLIP_VALUE, CLIP_VALUE)\n",
    "\n",
    "            gen_fake = critic(fake).reshape(-1)\n",
    "            loss_gen = -torch.mean(gen_fake)\n",
    "            \n",
    "            gen.zero_grad()\n",
    "            loss_gen.backward()\n",
    "            opt_gen.step()\n",
    "            \n",
    "            loop.set_description(f\"Epoch [{epoch}/{NUM_EPOCHS}]\")\n",
    "            loop.set_postfix(loss_d=loss_critic.item(), loss_g=loss_gen.item())\n",
    "            \n",
    "            step += 1\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            fake = gen(fixed_noise)\n",
    "            img_grid = vutils.make_grid(fake[:32], normalize=True)\n",
    "            vutils.save_image(img_grid, f\"{OUTPUT_DIR}/epoch_{epoch}.png\")\n",
    "\n",
    "    print(\"Training Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71daf4b7",
   "metadata": {},
   "source": [
    "## Inferência\n",
    "\n",
    "Após o treinamento, utilize o **Gerador** para produzir novas imagens a partir de **vetores de ruído aleatório**.\n",
    "Cada vetor servirá como ponto de partida no espaço latente, sendo transformado pelo modelo em uma amostra sintética do domínio aprendido.\n",
    "\n",
    "Durante a inferência:\n",
    "\n",
    "* Gere múltiplas imagens e visualize os resultados.\n",
    "* Analise a **qualidade e diversidade** das amostras produzidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d14ae553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images for 'landscape painting'...\n",
      "Data preparation complete!\n",
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [0/150]: 100%|██████████| 50/50 [00:05<00:00,  9.80it/s, loss_d=-1.47, loss_g=0.71]   \n",
      "Epoch [1/150]: 100%|██████████| 50/50 [00:04<00:00, 10.13it/s, loss_d=-1.53, loss_g=0.733]\n",
      "Epoch [2/150]: 100%|██████████| 50/50 [00:04<00:00, 10.83it/s, loss_d=-1.53, loss_g=0.727]\n",
      "Epoch [3/150]: 100%|██████████| 50/50 [00:04<00:00, 10.33it/s, loss_d=-1.54, loss_g=0.738]\n",
      "Epoch [4/150]: 100%|██████████| 50/50 [00:05<00:00,  9.80it/s, loss_d=-1.55, loss_g=0.739]\n",
      "Epoch [5/150]: 100%|██████████| 50/50 [00:05<00:00,  8.79it/s, loss_d=-1.54, loss_g=0.737]\n",
      "Epoch [6/150]: 100%|██████████| 50/50 [00:05<00:00,  9.39it/s, loss_d=-1.55, loss_g=0.739]\n",
      "Epoch [7/150]: 100%|██████████| 50/50 [00:05<00:00,  9.55it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [8/150]: 100%|██████████| 50/50 [00:05<00:00,  9.70it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [9/150]: 100%|██████████| 50/50 [00:05<00:00,  9.63it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [10/150]: 100%|██████████| 50/50 [00:05<00:00,  9.77it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [11/150]: 100%|██████████| 50/50 [00:05<00:00,  9.65it/s, loss_d=-1.54, loss_g=0.739]\n",
      "Epoch [12/150]: 100%|██████████| 50/50 [00:05<00:00,  9.85it/s, loss_d=-1.55, loss_g=0.739]\n",
      "Epoch [13/150]: 100%|██████████| 50/50 [00:05<00:00,  9.75it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [14/150]: 100%|██████████| 50/50 [00:05<00:00,  9.92it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [15/150]: 100%|██████████| 50/50 [00:05<00:00,  9.40it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [16/150]: 100%|██████████| 50/50 [00:05<00:00,  9.85it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [17/150]: 100%|██████████| 50/50 [00:05<00:00,  9.49it/s, loss_d=-1.54, loss_g=0.739]\n",
      "Epoch [18/150]: 100%|██████████| 50/50 [00:05<00:00,  9.77it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [19/150]: 100%|██████████| 50/50 [00:05<00:00,  9.73it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [20/150]: 100%|██████████| 50/50 [00:05<00:00,  9.55it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [21/150]: 100%|██████████| 50/50 [00:05<00:00,  9.63it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [22/150]: 100%|██████████| 50/50 [00:05<00:00,  9.09it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [23/150]: 100%|██████████| 50/50 [00:05<00:00,  8.92it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [24/150]: 100%|██████████| 50/50 [00:04<00:00, 10.03it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [25/150]: 100%|██████████| 50/50 [00:05<00:00,  9.08it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [26/150]: 100%|██████████| 50/50 [00:04<00:00, 10.05it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [27/150]: 100%|██████████| 50/50 [00:05<00:00,  9.62it/s, loss_d=-1.54, loss_g=0.735]\n",
      "Epoch [28/150]: 100%|██████████| 50/50 [00:05<00:00,  9.35it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [29/150]: 100%|██████████| 50/50 [00:05<00:00,  9.67it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [30/150]: 100%|██████████| 50/50 [00:04<00:00, 10.11it/s, loss_d=-1.54, loss_g=0.736]\n",
      "Epoch [31/150]: 100%|██████████| 50/50 [00:04<00:00, 10.04it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [32/150]: 100%|██████████| 50/50 [00:05<00:00,  9.48it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [33/150]: 100%|██████████| 50/50 [00:05<00:00,  9.76it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [34/150]: 100%|██████████| 50/50 [00:04<00:00, 10.12it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [35/150]: 100%|██████████| 50/50 [00:04<00:00, 10.08it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [36/150]: 100%|██████████| 50/50 [00:05<00:00,  9.70it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [37/150]: 100%|██████████| 50/50 [00:05<00:00,  9.67it/s, loss_d=-1.54, loss_g=0.73] \n",
      "Epoch [38/150]: 100%|██████████| 50/50 [00:05<00:00,  9.35it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [39/150]: 100%|██████████| 50/50 [00:04<00:00, 10.08it/s, loss_d=-1.54, loss_g=0.739]\n",
      "Epoch [40/150]: 100%|██████████| 50/50 [00:05<00:00,  9.22it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [41/150]: 100%|██████████| 50/50 [00:05<00:00,  9.70it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [42/150]: 100%|██████████| 50/50 [00:05<00:00,  9.40it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [43/150]: 100%|██████████| 50/50 [00:05<00:00,  9.57it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [44/150]: 100%|██████████| 50/50 [00:05<00:00,  9.53it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [45/150]: 100%|██████████| 50/50 [00:05<00:00,  9.18it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [46/150]: 100%|██████████| 50/50 [00:05<00:00,  9.26it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [47/150]: 100%|██████████| 50/50 [00:05<00:00,  9.92it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [48/150]: 100%|██████████| 50/50 [00:05<00:00,  9.22it/s, loss_d=-1.53, loss_g=0.718]\n",
      "Epoch [49/150]: 100%|██████████| 50/50 [00:05<00:00,  8.93it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [50/150]: 100%|██████████| 50/50 [00:05<00:00,  9.54it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [51/150]: 100%|██████████| 50/50 [00:04<00:00, 10.04it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [52/150]: 100%|██████████| 50/50 [00:05<00:00,  9.47it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [53/150]: 100%|██████████| 50/50 [00:05<00:00,  9.74it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [54/150]: 100%|██████████| 50/50 [00:05<00:00,  9.23it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [55/150]: 100%|██████████| 50/50 [00:05<00:00,  9.27it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [56/150]: 100%|██████████| 50/50 [00:05<00:00,  9.49it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [57/150]: 100%|██████████| 50/50 [00:05<00:00,  9.79it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [58/150]: 100%|██████████| 50/50 [00:05<00:00,  9.31it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [59/150]: 100%|██████████| 50/50 [00:05<00:00,  9.73it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [60/150]: 100%|██████████| 50/50 [00:05<00:00,  9.89it/s, loss_d=-1.55, loss_g=0.738]\n",
      "Epoch [61/150]: 100%|██████████| 50/50 [00:05<00:00,  9.55it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [62/150]: 100%|██████████| 50/50 [00:05<00:00,  9.81it/s, loss_d=-1.55, loss_g=0.738]\n",
      "Epoch [63/150]: 100%|██████████| 50/50 [00:05<00:00,  9.60it/s, loss_d=-1.55, loss_g=0.739]\n",
      "Epoch [64/150]: 100%|██████████| 50/50 [00:04<00:00, 10.07it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [65/150]: 100%|██████████| 50/50 [00:05<00:00,  9.71it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [66/150]: 100%|██████████| 50/50 [00:05<00:00,  9.67it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [67/150]: 100%|██████████| 50/50 [00:04<00:00, 10.05it/s, loss_d=-1.51, loss_g=0.721]\n",
      "Epoch [68/150]: 100%|██████████| 50/50 [00:05<00:00,  9.25it/s, loss_d=-1.55, loss_g=0.738] \n",
      "Epoch [69/150]: 100%|██████████| 50/50 [00:05<00:00,  9.72it/s, loss_d=-1.54, loss_g=0.735]\n",
      "Epoch [70/150]: 100%|██████████| 50/50 [00:05<00:00,  9.38it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [71/150]: 100%|██████████| 50/50 [00:04<00:00, 10.02it/s, loss_d=-1.48, loss_g=0.724]\n",
      "Epoch [72/150]: 100%|██████████| 50/50 [00:05<00:00,  9.18it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [73/150]: 100%|██████████| 50/50 [00:05<00:00,  9.47it/s, loss_d=-1.54, loss_g=0.726]\n",
      "Epoch [74/150]: 100%|██████████| 50/50 [00:05<00:00,  9.35it/s, loss_d=-1.55, loss_g=0.74]  \n",
      "Epoch [75/150]: 100%|██████████| 50/50 [00:05<00:00,  9.45it/s, loss_d=-0.596, loss_g=0.675]\n",
      "Epoch [76/150]: 100%|██████████| 50/50 [00:05<00:00,  9.32it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [77/150]: 100%|██████████| 50/50 [00:05<00:00,  9.76it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [78/150]: 100%|██████████| 50/50 [00:04<00:00, 10.15it/s, loss_d=-1.55, loss_g=0.74] \n",
      "Epoch [79/150]: 100%|██████████| 50/50 [00:05<00:00,  9.05it/s, loss_d=-1.24, loss_g=-0.662]\n",
      "Epoch [80/150]: 100%|██████████| 50/50 [00:05<00:00,  9.81it/s, loss_d=-1.55, loss_g=0.739]\n",
      "Epoch [81/150]: 100%|██████████| 50/50 [00:05<00:00,  9.37it/s, loss_d=-1.55, loss_g=0.741]\n",
      "Epoch [82/150]: 100%|██████████| 50/50 [00:05<00:00,  9.96it/s, loss_d=-1.54, loss_g=0.739]\n",
      "Epoch [83/150]: 100%|██████████| 50/50 [00:04<00:00, 10.09it/s, loss_d=-1.53, loss_g=0.726] \n",
      "Epoch [84/150]: 100%|██████████| 50/50 [00:05<00:00,  9.43it/s, loss_d=-1.54, loss_g=0.738]\n",
      "Epoch [85/150]: 100%|██████████| 50/50 [00:05<00:00,  9.96it/s, loss_d=-1.49, loss_g=0.735]\n",
      "Epoch [86/150]: 100%|██████████| 50/50 [00:05<00:00,  9.75it/s, loss_d=-1.55, loss_g=0.739]\n",
      "Epoch [87/150]: 100%|██████████| 50/50 [00:04<00:00, 10.22it/s, loss_d=-1.54, loss_g=0.737] \n",
      "Epoch [88/150]: 100%|██████████| 50/50 [00:04<00:00, 10.06it/s, loss_d=-1.55, loss_g=0.739]\n",
      "Epoch [89/150]: 100%|██████████| 50/50 [00:05<00:00,  9.24it/s, loss_d=-1.54, loss_g=0.736] \n",
      "Epoch [90/150]: 100%|██████████| 50/50 [00:05<00:00,  9.88it/s, loss_d=-1.55, loss_g=0.738]\n",
      "Epoch [91/150]: 100%|██████████| 50/50 [00:05<00:00,  9.61it/s, loss_d=-1.55, loss_g=0.739]\n",
      "Epoch [92/150]: 100%|██████████| 50/50 [00:05<00:00,  9.66it/s, loss_d=-1.54, loss_g=0.735] \n",
      "Epoch [93/150]: 100%|██████████| 50/50 [00:05<00:00,  8.91it/s, loss_d=-1.54, loss_g=0.735]   \n",
      "Epoch [94/150]: 100%|██████████| 50/50 [00:05<00:00,  9.01it/s, loss_d=-1.54, loss_g=0.737]\n",
      "Epoch [95/150]: 100%|██████████| 50/50 [00:05<00:00,  9.41it/s, loss_d=-1.54, loss_g=0.736]\n",
      "Epoch [96/150]: 100%|██████████| 50/50 [00:05<00:00,  9.42it/s, loss_d=-1.52, loss_g=0.732]\n",
      "Epoch [97/150]: 100%|██████████| 50/50 [00:05<00:00,  9.69it/s, loss_d=-0.636, loss_g=0.438]\n",
      "Epoch [98/150]: 100%|██████████| 50/50 [00:05<00:00,  9.80it/s, loss_d=-1.52, loss_g=0.728]\n",
      "Epoch [99/150]: 100%|██████████| 50/50 [00:05<00:00,  9.89it/s, loss_d=-1.53, loss_g=0.732]\n",
      "Epoch [100/150]: 100%|██████████| 50/50 [00:05<00:00,  9.16it/s, loss_d=-1.54, loss_g=0.734]\n",
      "Epoch [101/150]: 100%|██████████| 50/50 [00:05<00:00,  8.53it/s, loss_d=-1.54, loss_g=0.733] \n",
      "Epoch [102/150]: 100%|██████████| 50/50 [00:05<00:00,  8.44it/s, loss_d=-1.53, loss_g=0.732] \n",
      "Epoch [103/150]: 100%|██████████| 50/50 [00:05<00:00,  9.74it/s, loss_d=-1.53, loss_g=0.73]  \n",
      "Epoch [104/150]: 100%|██████████| 50/50 [00:05<00:00,  8.99it/s, loss_d=-1.53, loss_g=0.73] \n",
      "Epoch [105/150]: 100%|██████████| 50/50 [00:05<00:00,  9.76it/s, loss_d=-1.44, loss_g=0.698]\n",
      "Epoch [106/150]: 100%|██████████| 50/50 [00:05<00:00,  8.69it/s, loss_d=-1.43, loss_g=0.709] \n",
      "Epoch [107/150]: 100%|██████████| 50/50 [00:05<00:00,  9.30it/s, loss_d=-1.52, loss_g=0.725] \n",
      "Epoch [108/150]: 100%|██████████| 50/50 [00:06<00:00,  7.94it/s, loss_d=-1.51, loss_g=0.721]\n",
      "Epoch [109/150]: 100%|██████████| 50/50 [00:05<00:00,  8.59it/s, loss_d=-1.46, loss_g=0.707]\n",
      "Epoch [110/150]: 100%|██████████| 50/50 [00:05<00:00,  8.85it/s, loss_d=-1.5, loss_g=0.719]   \n",
      "Epoch [111/150]: 100%|██████████| 50/50 [00:05<00:00,  8.90it/s, loss_d=-1.48, loss_g=0.709]\n",
      "Epoch [112/150]: 100%|██████████| 50/50 [00:05<00:00,  9.71it/s, loss_d=-1.46, loss_g=0.697]\n",
      "Epoch [113/150]: 100%|██████████| 50/50 [00:05<00:00,  9.70it/s, loss_d=-1.34, loss_g=0.678]  \n",
      "Epoch [114/150]: 100%|██████████| 50/50 [00:05<00:00,  9.65it/s, loss_d=-1.46, loss_g=0.701]\n",
      "Epoch [115/150]: 100%|██████████| 50/50 [00:05<00:00,  9.33it/s, loss_d=-1.43, loss_g=0.692] \n",
      "Epoch [116/150]: 100%|██████████| 50/50 [00:05<00:00,  9.93it/s, loss_d=-1.44, loss_g=0.693]\n",
      "Epoch [117/150]: 100%|██████████| 50/50 [00:04<00:00, 10.04it/s, loss_d=-1.24, loss_g=0.58] \n",
      "Epoch [118/150]: 100%|██████████| 50/50 [00:05<00:00,  9.87it/s, loss_d=-1.46, loss_g=0.701]\n",
      "Epoch [119/150]: 100%|██████████| 50/50 [00:05<00:00,  9.49it/s, loss_d=-1.45, loss_g=0.694]\n",
      "Epoch [120/150]: 100%|██████████| 50/50 [00:05<00:00,  9.58it/s, loss_d=-1.41, loss_g=0.681]\n",
      "Epoch [121/150]: 100%|██████████| 50/50 [00:05<00:00,  8.91it/s, loss_d=-1.45, loss_g=0.699] \n",
      "Epoch [122/150]: 100%|██████████| 50/50 [00:05<00:00,  9.52it/s, loss_d=-1.45, loss_g=0.698]\n",
      "Epoch [123/150]: 100%|██████████| 50/50 [00:05<00:00,  8.97it/s, loss_d=-1.47, loss_g=0.704] \n",
      "Epoch [124/150]: 100%|██████████| 50/50 [00:05<00:00,  9.49it/s, loss_d=-1.44, loss_g=0.694]\n",
      "Epoch [125/150]: 100%|██████████| 50/50 [00:05<00:00,  9.87it/s, loss_d=-1.45, loss_g=0.699]\n",
      "Epoch [126/150]: 100%|██████████| 50/50 [00:05<00:00,  9.70it/s, loss_d=-1.3, loss_g=0.673] \n",
      "Epoch [127/150]: 100%|██████████| 50/50 [00:04<00:00, 10.01it/s, loss_d=-1.46, loss_g=0.702]\n",
      "Epoch [128/150]: 100%|██████████| 50/50 [00:05<00:00,  9.48it/s, loss_d=-1.41, loss_g=0.688]\n",
      "Epoch [129/150]: 100%|██████████| 50/50 [00:05<00:00,  9.80it/s, loss_d=-1.43, loss_g=0.688]\n",
      "Epoch [130/150]: 100%|██████████| 50/50 [00:05<00:00,  9.42it/s, loss_d=-1.47, loss_g=0.702]\n",
      "Epoch [131/150]: 100%|██████████| 50/50 [00:05<00:00,  9.42it/s, loss_d=-1.45, loss_g=0.702]\n",
      "Epoch [132/150]: 100%|██████████| 50/50 [00:05<00:00,  9.51it/s, loss_d=-1.44, loss_g=0.696]\n",
      "Epoch [133/150]: 100%|██████████| 50/50 [00:05<00:00,  9.85it/s, loss_d=-1.38, loss_g=0.679]\n",
      "Epoch [134/150]: 100%|██████████| 50/50 [00:05<00:00,  9.58it/s, loss_d=-1.46, loss_g=0.702]\n",
      "Epoch [135/150]: 100%|██████████| 50/50 [00:05<00:00,  9.52it/s, loss_d=-1.46, loss_g=0.699]\n",
      "Epoch [136/150]: 100%|██████████| 50/50 [00:05<00:00,  9.45it/s, loss_d=-1.44, loss_g=0.691]\n",
      "Epoch [137/150]: 100%|██████████| 50/50 [00:05<00:00,  9.33it/s, loss_d=-1.43, loss_g=0.683]\n",
      "Epoch [138/150]: 100%|██████████| 50/50 [00:05<00:00,  9.44it/s, loss_d=-1.3, loss_g=0.498] \n",
      "Epoch [139/150]: 100%|██████████| 50/50 [00:05<00:00,  9.60it/s, loss_d=-1.42, loss_g=0.683]\n",
      "Epoch [140/150]: 100%|██████████| 50/50 [00:05<00:00,  9.47it/s, loss_d=-1.41, loss_g=0.689]\n",
      "Epoch [141/150]: 100%|██████████| 50/50 [00:05<00:00,  9.29it/s, loss_d=-1.46, loss_g=0.698]\n",
      "Epoch [142/150]: 100%|██████████| 50/50 [00:05<00:00,  9.13it/s, loss_d=-1.47, loss_g=0.709]\n",
      "Epoch [143/150]: 100%|██████████| 50/50 [00:05<00:00,  9.52it/s, loss_d=-1.43, loss_g=0.695]\n",
      "Epoch [144/150]: 100%|██████████| 50/50 [00:05<00:00,  9.68it/s, loss_d=-1.46, loss_g=0.704]\n",
      "Epoch [145/150]: 100%|██████████| 50/50 [00:05<00:00,  9.64it/s, loss_d=-1.4, loss_g=0.671] \n",
      "Epoch [146/150]: 100%|██████████| 50/50 [00:05<00:00,  9.61it/s, loss_d=-1.46, loss_g=0.701]\n",
      "Epoch [147/150]: 100%|██████████| 50/50 [00:05<00:00,  9.62it/s, loss_d=-1.39, loss_g=0.675]\n",
      "Epoch [148/150]: 100%|██████████| 50/50 [00:05<00:00,  9.58it/s, loss_d=-1.46, loss_g=0.696]\n",
      "Epoch [149/150]: 100%|██████████| 50/50 [00:05<00:00,  9.58it/s, loss_d=-1.44, loss_g=0.687]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
